{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0128a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "#pd.set_option(\"display.max_colwidth\", -1)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#library that contains punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65b1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "#defining function for tokenization\n",
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = re.split('W+',text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "#importing nlp library\n",
    "import nltk\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output=\"\".join([i for i in text if i not in stopwords])\n",
    "    return output\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b246db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentence', 'section_nr','has_citation','last_section_title','Labels']\n",
    "cols1 = ['sentence', 'section_nr','has_citation','last_section_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2d1181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>section_nr</th>\n",
       "      <th>has_citation</th>\n",
       "      <th>last_section_title</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This live defined as 1 00 Defination</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Defination</td>\n",
       "      <td>Defination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A sunshine be a maven that shine 1 00 Defination</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Defination</td>\n",
       "      <td>Defination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e set galaxy as the group of star 1 00 Defination</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Defination</td>\n",
       "      <td>Defination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e ask that these were in all likeliness stimulate by the 1 00 Hypothesis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hypothesis</td>\n",
       "      <td>Hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information technology could trace theorise that 4 00 Hypothesis</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hypothesis</td>\n",
       "      <td>Hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>there comprise some limitation and boundary conditions touch on to this sketch 87 00 limitations and future topics</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>limitations and future topics</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>using a laboratory experimentation is associated with limitations related to external monitoring artificial setting and deficiency of anonymity 87 00 limitations and future topics</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>limitations and future topics</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>as users tend to behave impulsively with mobile virtual application appdynamics 2017  these limitations could get resulted in to a lesser extent impulsive reaction 87 10 limitations and future topics</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>limitations and future topics</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18154</th>\n",
       "      <td>tertiary using yes  no resolution choice for evaluating appraisals cost penurious and thusly resultant in certain limit 87 00 limitations and future topics</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>limitations and future topics</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18155</th>\n",
       "      <td>fifth our report centre on highly negative incidents operating theater else of ordinary incidents which live a typical confinement of critical incident technique gremler 2004  87 10 limitations and future topics</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>limitations and future topics</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                   sentence  \\\n",
       "0                                                                                                                                                                                      This live defined as 1 00 Defination   \n",
       "1                                                                                                                                                                          A sunshine be a maven that shine 1 00 Defination   \n",
       "2                                                                                                                                                                         e set galaxy as the group of star 1 00 Defination   \n",
       "3                                                                                                                                                  e ask that these were in all likeliness stimulate by the 1 00 Hypothesis   \n",
       "4                                                                                                                                                          Information technology could trace theorise that 4 00 Hypothesis   \n",
       "...                                                                                                                                                                                                                     ...   \n",
       "18151                                                                                                   there comprise some limitation and boundary conditions touch on to this sketch 87 00 limitations and future topics    \n",
       "18152                                  using a laboratory experimentation is associated with limitations related to external monitoring artificial setting and deficiency of anonymity 87 00 limitations and future topics    \n",
       "18153              as users tend to behave impulsively with mobile virtual application appdynamics 2017  these limitations could get resulted in to a lesser extent impulsive reaction 87 10 limitations and future topics    \n",
       "18154                                                          tertiary using yes  no resolution choice for evaluating appraisals cost penurious and thusly resultant in certain limit 87 00 limitations and future topics    \n",
       "18155  fifth our report centre on highly negative incidents operating theater else of ordinary incidents which live a typical confinement of critical incident technique gremler 2004  87 10 limitations and future topics    \n",
       "\n",
       "       section_nr  has_citation              last_section_title      Labels  \n",
       "0               1           0.0                      Defination  Defination  \n",
       "1               1           0.0                      Defination  Defination  \n",
       "2               1           0.0                      Defination  Defination  \n",
       "3               1           0.0                      Hypothesis  Hypothesis  \n",
       "4               4           0.0                      Hypothesis  Hypothesis  \n",
       "...           ...           ...                             ...         ...  \n",
       "18151          87           0.0  limitations and future topics   limitation  \n",
       "18152          87           0.0  limitations and future topics   limitation  \n",
       "18153          87           1.0  limitations and future topics   limitation  \n",
       "18154          87           0.0  limitations and future topics   limitation  \n",
       "18155          87           1.0  limitations and future topics   limitation  \n",
       "\n",
       "[18156 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEXT PREPROCESSING\n",
    "#get unlabelled data provided by professor\n",
    "df1 = pd.read_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\nlpaug_concat.csv')\n",
    "df1['sentence']= df1['sentence'].apply(lambda x:remove_punctuation(x))\n",
    "#applying function to the column\n",
    "df1['sentence']= df1['sentence'].apply(lambda x: tokenization(x))\n",
    "#applying the function\n",
    "df1['sentence']= df1['sentence'].apply(lambda x:remove_stopwords(x))\n",
    "#applying function to the column\n",
    "df1['sentence']= df1['sentence'].apply(lambda x: tokenization(x))\n",
    "df1['sentence']=df1['sentence'].apply(lambda x:lemmatizer(x))\n",
    "#list to string\n",
    "df1['sentence'] = [' '.join(map(str, l)) for l in df1['sentence']]\n",
    "df1 = df1[cols]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd94187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\preprocessed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b036251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>section_nr</th>\n",
       "      <th>has_citation</th>\n",
       "      <th>last_section_title</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The aim of this thesis was to gain an understanding of the diametrical deformation behaviour of acetabular cups and shells following impaction into the reamed acetabulum 1 0 Research Aim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Research Aim</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The aim is to develop finite element models using explicit dynamics to mimic mallet blows during cupshell insertion initially using simplified experimentally validated foam models to represent the acetabulum 1 0 Research Objective</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Research Objective</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Determine the relationship between the size of interference between the cup and cavity and deformation for different cup types 1 0 Research Objective</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Research Objective</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investigate the influence of nonuniform cup support and varying the orientation of the component in the cavity on deformation 1 0 Research Objective</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Research Objective</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Examine the influence of errors during reaming of the acetabulum which introduce ovality to the cavity 1 0 Research Objective</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Research Objective</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>the moment of enjoyment on the pattern to raise be material than on the intention to keep on the premium subscription 39 0 hypothesis outcome</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>hypothesis outcome</td>\n",
       "      <td>Hypothesis Result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Information technology substantiate the hypothesis that a good nighttime sleep can increase the productiveness 10 0 hypothesis outcome</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>hypothesis outcome</td>\n",
       "      <td>Hypothesis Result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>information engineering science rejects the surmisal that corrode rugularly serve non urinate any wallop in weight 10 0 hypothesis outcome</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>hypothesis outcome</td>\n",
       "      <td>Hypothesis Result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>the supposition stern follow agreed on the cornerstone of the result 10 0 hypothesis outcome</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>hypothesis outcome</td>\n",
       "      <td>Hypothesis Result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>the final result prove the possibility that the rainforest 10 0 hypothesis outcome</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>hypothesis outcome</td>\n",
       "      <td>Hypothesis Result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   sentence  \\\n",
       "0                                                The aim of this thesis was to gain an understanding of the diametrical deformation behaviour of acetabular cups and shells following impaction into the reamed acetabulum 1 0 Research Aim   \n",
       "1    The aim is to develop finite element models using explicit dynamics to mimic mallet blows during cupshell insertion initially using simplified experimentally validated foam models to represent the acetabulum 1 0 Research Objective   \n",
       "2                                                                                     Determine the relationship between the size of interference between the cup and cavity and deformation for different cup types 1 0 Research Objective   \n",
       "3                                                                                      Investigate the influence of nonuniform cup support and varying the orientation of the component in the cavity on deformation 1 0 Research Objective   \n",
       "4                                                                                                             Examine the influence of errors during reaming of the acetabulum which introduce ovality to the cavity 1 0 Research Objective   \n",
       "..                                                                                                                                                                                                                                      ...   \n",
       "577                                                                                          the moment of enjoyment on the pattern to raise be material than on the intention to keep on the premium subscription 39 0 hypothesis outcome    \n",
       "578                                                                                                 Information technology substantiate the hypothesis that a good nighttime sleep can increase the productiveness 10 0 hypothesis outcome    \n",
       "579                                                                                             information engineering science rejects the surmisal that corrode rugularly serve non urinate any wallop in weight 10 0 hypothesis outcome    \n",
       "580                                                                                                                                           the supposition stern follow agreed on the cornerstone of the result 10 0 hypothesis outcome    \n",
       "581                                                                                                                                                     the final result prove the possibility that the rainforest 10 0 hypothesis outcome    \n",
       "\n",
       "     section_nr  has_citation   last_section_title             Labels  \n",
       "0             1             0         Research Aim                Aim  \n",
       "1             1             0   Research Objective                Aim  \n",
       "2             1             0   Research Objective                Aim  \n",
       "3             1             0   Research Objective                Aim  \n",
       "4             1             0   Research Objective                Aim  \n",
       "..          ...           ...                  ...                ...  \n",
       "577          39             0  hypothesis outcome   Hypothesis Result  \n",
       "578          10             0  hypothesis outcome   Hypothesis Result  \n",
       "579          10             0  hypothesis outcome   Hypothesis Result  \n",
       "580          10             0  hypothesis outcome   Hypothesis Result  \n",
       "581          10             0  hypothesis outcome   Hypothesis Result  \n",
       "\n",
       "[582 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get unlabelled data provided by professor\n",
    "test = pd.read_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\test_concat.csv')\n",
    "\n",
    "test['sentence']= test['sentence'].apply(lambda x:remove_punctuation(x))\n",
    "#applying function to the column\n",
    "test['sentence']= test['sentence'].apply(lambda x: tokenization(x))\n",
    "#applying the function\n",
    "test['sentence']= test['sentence'].apply(lambda x:remove_stopwords(x))\n",
    "#applying function to the column\n",
    "test['sentence']= test['sentence'].apply(lambda x: tokenization(x))\n",
    "test['sentence']=test['sentence'].apply(lambda x:lemmatizer(x))\n",
    "#list to string\n",
    "test['sentence'] = [' '.join(map(str, l)) for l in test['sentence']]\n",
    "test = test[cols]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68706ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4248e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
