{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6803ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44ca5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rule based training and testing dataset\n",
    "df1 = pd.read_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\rule_train_data.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\nitis\\Sentence classification\\theis_final\\rule_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32919e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypothesis Result         2016\n",
       "Aim                       1744\n",
       "Research Question         1712\n",
       "Contribution              1680\n",
       "Hypothesis                1674\n",
       "Defination                1512\n",
       "Emperical Result          1476\n",
       "Relation to literature    1452\n",
       "Motivation                1360\n",
       "limitation                1284\n",
       "Future work               1170\n",
       "Method                    1076\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e588756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for training and testing with input and output labels\n",
    "X_train = df1['sentence']\n",
    "y_train = df1['Labels']\n",
    "X_test = test['sentence']\n",
    "y_test = test['Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45ed70",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ad3cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.47594501718213056\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                   Aim       0.11      0.78      0.19        18\n",
      "          Contribution       0.79      0.77      0.78        57\n",
      "            Defination       0.58      0.28      0.38        25\n",
      "      Emperical Result       0.68      0.87      0.76        46\n",
      "           Future work       0.89      0.26      0.40        96\n",
      "            Hypothesis       0.37      0.16      0.22        70\n",
      "     Hypothesis Result       0.43      0.07      0.12        43\n",
      "                Method       0.71      0.63      0.67        43\n",
      "            Motivation       0.20      0.38      0.26        24\n",
      "Relation to literature       0.18      0.04      0.06        54\n",
      "     Research Question       0.60      0.97      0.74        67\n",
      "            limitation       0.49      0.77      0.60        39\n",
      "\n",
      "              accuracy                           0.48       582\n",
      "             macro avg       0.50      0.50      0.43       582\n",
      "          weighted avg       0.56      0.48      0.45       582\n",
      "\n",
      "Confusion Matrix: [[14  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 8 44  0  1  0  0  0  0  2  0  2  0]\n",
      " [ 5  3  7  0  0  0  0  0  6  3  1  0]\n",
      " [ 1  0  2 40  0  0  0  0  0  3  0  0]\n",
      " [28  4  0  1 25  0  0  0  6  0 20 12]\n",
      " [38  0  1  0  0 11  3  3 12  0  2  0]\n",
      " [ 1  3  0 15  2 19  3  0  0  0  0  0]\n",
      " [11  0  0  0  0  0  0 27  0  3  2  0]\n",
      " [ 8  0  0  0  0  0  1  0  9  0  6  0]\n",
      " [ 9  1  1  1  0  0  0  6  9  2  6 19]\n",
      " [ 1  0  1  0  0  0  0  0  0  0 65  0]\n",
      " [ 2  1  0  1  1  0  0  2  2  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "                ('chi',  SelectKBest(chi2, k=1200)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fa7e7",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec205281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.697594501718213\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                   Aim       0.34      0.56      0.43        18\n",
      "          Contribution       0.92      0.98      0.95        57\n",
      "            Defination       0.78      0.72      0.75        25\n",
      "      Emperical Result       0.68      0.96      0.79        46\n",
      "           Future work       0.94      0.62      0.75        96\n",
      "            Hypothesis       0.68      0.81      0.74        70\n",
      "     Hypothesis Result       0.00      0.00      0.00        43\n",
      "                Method       0.86      0.98      0.91        43\n",
      "            Motivation       0.40      0.50      0.44        24\n",
      "Relation to literature       0.55      0.11      0.18        54\n",
      "     Research Question       0.89      0.93      0.91        67\n",
      "            limitation       0.41      1.00      0.58        39\n",
      "\n",
      "              accuracy                           0.70       582\n",
      "             macro avg       0.62      0.68      0.62       582\n",
      "          weighted avg       0.68      0.70      0.66       582\n",
      "\n",
      "Confusion Matrix: [[10  0  0  0  0  0  0  0  7  0  1  0]\n",
      " [ 0 56  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  3 18  0  0  0  0  0  4  0  0  0]\n",
      " [ 0  0  0 44  2  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  2 60  1  0  0  3  4  1 23]\n",
      " [ 4  0  3  0  0 57  1  1  4  0  0  0]\n",
      " [ 0  0  0 15  2 26  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 42  0  0  1  0]\n",
      " [ 7  0  0  3  0  0  0  0 12  0  2  0]\n",
      " [ 3  2  0  1  0  0  0  6  0  6  3 33]\n",
      " [ 3  0  2  0  0  0  0  0  0  0 62  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                 ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a31ec",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018370f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6168384879725086\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                   Aim       0.25      0.83      0.38        18\n",
      "          Contribution       0.94      0.88      0.91        57\n",
      "            Defination       0.36      0.56      0.44        25\n",
      "      Emperical Result       0.69      0.96      0.80        46\n",
      "           Future work       0.86      0.61      0.72        96\n",
      "            Hypothesis       0.47      0.29      0.35        70\n",
      "     Hypothesis Result       1.00      0.09      0.17        43\n",
      "                Method       0.72      0.98      0.83        43\n",
      "            Motivation       0.22      0.46      0.30        24\n",
      "Relation to literature       0.40      0.07      0.12        54\n",
      "     Research Question       0.93      0.93      0.93        67\n",
      "            limitation       0.53      0.87      0.66        39\n",
      "\n",
      "              accuracy                           0.62       582\n",
      "             macro avg       0.61      0.63      0.55       582\n",
      "          weighted avg       0.68      0.62      0.59       582\n",
      "\n",
      "Confusion Matrix: [[15  0  0  0  0  0  0  0  0  2  1  0]\n",
      " [ 2 50  0  0  0  0  0  1  0  4  0  0]\n",
      " [ 0  2 14  0  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0 44  2  0  0  0  0  0  0  0]\n",
      " [11  1  4  2 59  1  0  4  4  0  0 10]\n",
      " [12  0 13  0  0 20  0  4 21  0  0  0]\n",
      " [ 3  0  0 12  2 22  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 42  0  0  1  0]\n",
      " [10  0  0  3  0  0  0  0 11  0  0  0]\n",
      " [ 7  0  3  3  5  0  0  6  3  4  3 20]\n",
      " [ 1  0  2  0  0  0  0  0  2  0 62  0]\n",
      " [ 0  0  3  0  1  0  0  1  0  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                    ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3bb7c",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed39ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5945017182130584\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                   Aim       0.27      0.72      0.39        18\n",
      "          Contribution       0.93      0.98      0.96        57\n",
      "            Defination       0.54      0.52      0.53        25\n",
      "      Emperical Result       0.80      0.93      0.86        46\n",
      "           Future work       0.87      0.27      0.41        96\n",
      "            Hypothesis       0.58      0.54      0.56        70\n",
      "     Hypothesis Result       1.00      0.02      0.05        43\n",
      "                Method       0.82      0.98      0.89        43\n",
      "            Motivation       0.28      0.46      0.34        24\n",
      "Relation to literature       0.25      0.06      0.09        54\n",
      "     Research Question       0.60      0.93      0.73        67\n",
      "            limitation       0.42      0.97      0.58        39\n",
      "\n",
      "              accuracy                           0.59       582\n",
      "             macro avg       0.61      0.62      0.53       582\n",
      "          weighted avg       0.66      0.59      0.55       582\n",
      "\n",
      "Confusion Matrix: [[13  0  0  0  0  0  0  0  5  0  0  0]\n",
      " [ 0 56  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  3 13  0  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0 43  2  0  0  0  0  1  0  0]\n",
      " [ 5  1  2  0 26  0  0  2  3  6 32 19]\n",
      " [12  0  7  0  0 38  0  1 12  0  0  0]\n",
      " [ 0  0  0 11  2 28  1  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0 42  0  0  1  0]\n",
      " [13  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  6  0  3  8 34]\n",
      " [ 3  0  2  0  0  0  0  0  0  0 62  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1 38]]\n"
     ]
    }
   ],
   "source": [
    "rf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                     ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afae73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
